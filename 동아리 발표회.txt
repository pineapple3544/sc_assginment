2023년 한 해 동안 유행한 생성형 인공지능에 대해 공부해보고 싶어 어떤 생성형 인공지능에 대해 공부해볼지 고민하다가
우연한 인터넷의 알고리즘으로 보게 된 ai cover 노래들을 듣게 되었고 이에 흥미가 크게 생겨 음성 합성 모델에 대해 탐구하기 시작했고 곧이어 rvc,ddsp-svc,so-vits-svc,diff-svc 모델들이 있다는 것을 알게되었고 각각의 특징들을 알게 되었고 시간이 많지 않았기 때문에 적은 양의 데이터셋으로도 좋은 품질을 뽑을 수 있는 rvc을 탐구하고 사용해보기로 함

rvc모델은 크게 세가지 구조로 인코더,신디사이저,보코더로 이루어지는데 
인코더는 성 샘플로부터 화자의 특징을 추출하는 신경망으로 인코더는 음성 샘플을 80차원의 멜 스펙트로그램으로 변환하고, 이를 256차원의 임베딩 벡터로 압축하는데. 이 벡터는 화자의 음색, 발음, 강세 등을 나타냄
신디사이저는 텍스트를 음성으로 변환하는 신경망으로 신디사이저는 Tacotron 2라는 모델을 사용하며, 텍스트를 80차원의 멜 스펙트로그램으로 변환함. 신디사이저는 인코더에서 생성된 임베딩 벡터를 입력으로 받아, 텍스트와 화자의 특징을 결합하는데 사용됨
보코더는 음성의 품질을 향상시키는 신경망으로 보코더는 WaveRNN이라는 모델을 사용하며, 멜 스펙트로그램을 24kHz의 원시 오디오 신호로 변환하고. 보코더는 신디사이저에서 생성된 멜 스펙트로그램을 입력으로 받아, 음성의 자연스러움과 선명도를 높임.

rvc모델의 사용을 위한 작업 환경의 구축을 위해 구글의 제공하는 클라우드 기반의 컴퓨팅 서비스인 구글 코랩에서 작업 환경을 구축하고 데이터 학습을 위한 준비도 함

rvc모델의 학습을 위해 제일 먼저 데이터셋을 만들어야 함으로 적당한 사람의 녹음 파일이나 노래 파일을 다운받아 Ultimate Vocal Remover(이하 uvr)등으로 배경음을 제거하여 순수 목소리 파일을 이용해 데이터셋을 제작해 구글 코랩 파일이 있는 구글 드라이브에 데이터셋을 업로드 함

그 다음 데이터 전처리 과정을 거친 후 epochs의 수치를 설정하고 학습을 진행함

학습을 완료한 후 index파일도 학습하고 모델 파일을 저장하고 음성 합성을 위해 파일의 구조를 변경한 다음 모델을 이용해 음성 합성을 진행하고 해당 내용을 동아리발표회에서 발표함